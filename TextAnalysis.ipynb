{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['love', 'my', 'dalmation', 'please'] classified as : 0\n",
      "['stupid', 'garbage'] classified as : 1\n"
     ]
    }
   ],
   "source": [
    "#coding:utf-8\n",
    "# Naive Bayes Application: Filtering Web Site's Malicious Messages\n",
    "# The model is a set-of-words model that only takes the appearance of each word as a feature\n",
    "# and each word in the word bag model can appear multiple times\n",
    "from numpy import *\n",
    "# Vocabularies to vector conversion function\n",
    "def loadDataSet():\n",
    "    # function creates some experimental samples, returns the first variable is the collection of documents after this segmentation,\n",
    "    # the second variable is a collection of class labels\n",
    "    postingList = [['my','dog','has','flea','problems','help','please'],\n",
    "                   ['maybe','not','take','him','to','dog','park','stupid'],\n",
    "                   ['my','dalmation','is','so','cute','I','love','him'],\n",
    "                   ['stop','posting','stupid','worthless','garbage'],\n",
    "                   ['mr','licks','ate','my','steak','how','to','stop','him'],\n",
    "                   ['quit','buying','worthless','dog','food','stupid']]\n",
    "    classVec = [0 , 1 , 0 , 1 , 0 , 1] # 1 for insulting text, 0 for normal speech\n",
    "    return postingList , classVec\n",
    "\n",
    "def createVocabList(dataSet):\n",
    "    # Create a list of unique words that appear in all documents\n",
    "    vocabSet = set([]) # Create an empty set\n",
    "    for document in dataSet :\n",
    "        vocabSet = vocabSet | set(document) # Create a union of two collections\n",
    "    return list(vocabSet)\n",
    "\n",
    "#Functions in the word set model\n",
    "def setOfWords2Vec(vocabList , inputSet):\n",
    "    # The input parameters of the function are a vocabulary and a document, the output document vector,\n",
    "    # each element of the vector is 0 or 1, indicating whether the words in the vocabulary appear in the input document\n",
    "    # Create a vector with 0 elements in it\n",
    "    returnVec = [0] * len(vocabList)\n",
    "    for word in inputSet:\n",
    "        if word in vocabList:\n",
    "            returnVec[vocabList.index(word)] = 1\n",
    "        else:print(\"the word : %s is not in my Vocabulary !\" % word)\n",
    "    return returnVec\n",
    "\n",
    "# Bag of words model function\n",
    "def bagOfWords2Vec(vocabList , inputSet):\n",
    "    # The input parameters of the function are a vocabulary and a document, the output document vector,\n",
    "    # each element of the vector is 0 or 1, indicating whether the words in the vocabulary appear in the input document\n",
    "    # Create a vector with 0 elements in it\n",
    "    returnVec = [0] * len(vocabList)\n",
    "    for word in inputSet:\n",
    "        if word in vocabList:\n",
    "            returnVec[vocabList.index(word)] += 1\n",
    "        else:print(\"the word : %s is not in my Vocabulary !\" % word)\n",
    "    return returnVec\n",
    "\n",
    "# Naive Bayes Classifier Training Function\n",
    "def trainNBO(trainMatrix , trainCategory):\n",
    "    numTrainDocs = len(trainMatrix)\n",
    "    numWords = len(trainMatrix[0])\n",
    "    pAbusive = sum(trainCategory)/float(numTrainDocs)\n",
    "    p0Num = ones(numWords);p1Num = ones(numWords)\n",
    "    p0Denom = 2.0;p1Denom = 2.0\n",
    "    # x vector sum\n",
    "    for i in range(numTrainDocs):\n",
    "        if trainCategory[i] == 1:\n",
    "            p1Num += trainMatrix[i]\n",
    "            p1Denom += sum(trainMatrix[i])\n",
    "        else:\n",
    "            p0Num += trainMatrix[i]\n",
    "            p0Denom += sum(trainMatrix[i])\n",
    "    # Divide each element\n",
    "    p1Vect = log(p1Num/p1Denom) #change to log()\n",
    "    p0Vect = log(p0Num/p0Denom) #change to log()\n",
    "    return p0Vect , p1Vect , pAbusive\n",
    "\n",
    "# Naive Bayes Classifier Training Function\n",
    "def classifyNB(vec2Classify , p0Vec , p1Vec , pClass1):\n",
    "    # Equivalent to posterior probability: probability density multiplied by the prior probability\n",
    "    p1 = sum(vec2Classify*p1Vec) + log(pClass1)\n",
    "    p0 = sum(vec2Classify*p0Vec) + log(1-pClass1)\n",
    "    if p1 > p0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Convenient function that encapsulates all operations to save time entering code\n",
    "listOPosts , listClasses = loadDataSet()\n",
    "\n",
    "myVocabList = createVocabList(listOPosts)\n",
    "trainMat = []\n",
    "\n",
    "for postinDoc in listOPosts:\n",
    "    trainMat.append(setOfWords2Vec(myVocabList,postinDoc))\n",
    "    #print (setOfWords2Vec(myVocabList,postinDoc))\n",
    "p0V , p1V , pAb = trainNBO(array(trainMat) , array(listClasses))\n",
    "\n",
    "testEntry = ['love' , 'my' , 'dalmation', 'please']\n",
    "thisDoc = array(setOfWords2Vec(myVocabList , testEntry))\n",
    "print(testEntry , 'classified as :' ,classifyNB(thisDoc , p0V ,p1V ,pAb))\n",
    "testEntry = ['stupid' , 'garbage']\n",
    "thisDoc = array(setOfWords2Vec(myVocabList, testEntry))\n",
    "print(testEntry, 'classified as :', classifyNB(thisDoc, p0V, p1V, pAb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
